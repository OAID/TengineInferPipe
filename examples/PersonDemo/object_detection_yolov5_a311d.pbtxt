# Images on CPU coming into and out of the graph.
input_stream: "input_frame"
output_stream: "output_detect"

# Transforms the input image on CPU to a 320x320 image. To scale the image, by
# default it uses the STRETCH scale mode that maps the entire input image to the
# entire transformed image. As a result, image aspect ratio may be changed and
# objects in the image may be deformed (stretched or squeezed), but the object
# detection model used in this graph is agnostic to that deformation.
node: {
  calculator: "ImageTransformationCalculator"
  input_stream: "IMAGE:input_frame"
  output_stream: "IMAGE:transformed_input_frame"
  output_stream: "LETTERBOX_PADDING:image_pad"
  node_options: {
    [type.googleapis.com/mediapipe.ImageTransformationCalculatorOptions] {
      output_width: 640
      output_height: 384
      scale_mode: FIT
    }
  }
}

# Converts the transformed input image on CPU into an image tensor stored as a
# TfLiteTensor.
node {
  calculator: "TengineConverterCalculator"
  input_stream: "IMAGE:transformed_input_frame"
  output_stream: "ARRAYS:image_tensor"
  node_options: {
    [type.googleapis.com/mediapipe.TengineConverterCalculatorOptions] {
      tensor_mean: {val1:0 val2:0 val3:0}
      tensor_scale: {val1:0.003921569 val2:0.003921569 val3:0.003921569}
    }
  }
}

# Runs a TensorFlow Lite model on CPU that takes an image tensor and outputs a
# vector of tensors representing, for instance, detection boxes/keypoints and
# scores.
node {
  calculator: "TengineInferenceCalculator"
  input_stream: "ARRAYS:image_tensor"
  output_stream: "ARRAYS:detection_tensors"
  output_stream: "TENSOR_SHAPE:tensor_shapes"
  output_stream: "QUANT_PARAM:quant_param"
  node_options: {
    [type.googleapis.com/mediapipe.TengineInferenceCalculatorOptions] {
      model_path: "../models/yolov5s_640x384_uint8.tmfile"
      data_type: "uint8"
      output_num: 3
      max_dim: 5
      yolov5_focus: true
      tengine_backend: "timvx"
    }
  }
}

# Decodes the detection tensors generated by the TensorFlow Lite model, based on
# the SSD anchors and the specification in the options, into a vector of
# detections. Each detection describes a detected object.
node {
  calculator: "TengineYolov5TensorsToDetectionsCalculator"
  input_stream: "ARRAYS:detection_tensors"
  input_stream: "PADDING:image_pad"
  input_stream: "TENSOR_SHAPE:tensor_shapes"
  input_stream: "QUANT_PARAM:quant_param"
  output_stream: "DETECTIONS:detections"
  node_options: {
    [type.googleapis.com/mediapipe.TengineYolov5TensorsToDetectionsCalculatorOptions] {
      num_classes: 3
      num_boxes: 3
      num_coords: 4
      img_width: 640
      img_height: 384
      min_score_thresh: 0.5
      sigmoid_score: true
      data_type: "uint8"
    }
  }
}

# Performs non-max suppression to remove excessive detections.
node {
  calculator: "NonMaxSuppressionCalculator"
  input_stream: "detections"
  output_stream: "output_detect"
  node_options: {
    [type.googleapis.com/mediapipe.NonMaxSuppressionCalculatorOptions] {
      min_suppression_threshold: 0.4
      # max_num_detections: 100
      overlap_type: INTERSECTION_OVER_UNION
      return_empty_detections: true
    }
  }
}
